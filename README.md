# Ensemble Learning : Stacking 2 Niveaux vs ModÃ¨les Individuels en R

## Description du Projet

Ce projet implÃ©mente et compare une architecture de **Stacking Ã  2 niveaux** avec des modÃ¨les individuels sur **trois datasets de domaines diffÃ©rents** pour tirer des conclusions gÃ©nÃ©ralisables sur l'efficacitÃ© du stacking.

L'objectif est de dÃ©montrer que la combinaison intelligente de modÃ¨les diversifiÃ©s (ensemble learning) surpasse les modÃ¨les utilisÃ©s individuellement, et d'analyser comment cette amÃ©lioration varie selon la **diversitÃ© des modÃ¨les** (corrÃ©lation des prÃ©dictions), la **taille du dataset**, et la **dimensionnalitÃ© des features**.

---

## Architecture du Stacking

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   DONNÃ‰ES D'ENTRÃ‰E (3 Datasets)                        â”‚
â”‚  Ames Housing | Pima Diabetes | Bank Marketing (Financial/Commercial)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚     NIVEAU 0 (Base)     â”‚
          â”‚   5 ModÃ¨les DiversifiÃ©s â”‚
          â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
          â”‚  ğŸŒ² Random Forest       â”‚
          â”‚  ğŸ“Š SVM (Radial)        â”‚
          â”‚  ğŸ“ˆ RÃ©gression Logist.  â”‚
          â”‚  ğŸ¯ KNN                 â”‚
          â”‚  ğŸ“‰ Naive Bayes         â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
              Out-of-Fold Predictions
              (Validation CroisÃ©e 5-Fold)
                       â”‚
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚    NIVEAU 1 (Meta)      â”‚
          â”‚   2 Meta-ModÃ¨les        â”‚
          â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
          â”‚  ğŸ”· Ridge Regression    â”‚
          â”‚  ğŸš€ XGBoost             â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
              PrÃ©dictions Finales
```

### Pourquoi ces choix architecturaux ?

#### ModÃ¨les de Niveau 0 (Base Learners)

| ModÃ¨le | Type | Justification |
|--------|------|---------------|
| **Random Forest** | Bagging, Non-linÃ©aire | Robuste aux outliers, gÃ¨re bien les interactions entre features, faible variance grÃ¢ce au bagging de multiples arbres |
| **SVM (Radial)** | Kernel method | Excellent en haute dimension, frontiÃ¨res de dÃ©cision complexes via le noyau RBF, approche par marge maximale |
| **RÃ©gression Logistique** | LinÃ©aire | ModÃ¨le linÃ©aire simple â†’ apporte de la diversitÃ© face aux modÃ¨les non-linÃ©aires, interprÃ©table |
| **KNN** | Instance-based | Approche non-paramÃ©trique, capture les patterns locaux dans l'espace des features, complÃ©ment des mÃ©thodes globales |
| **Naive Bayes** | Probabiliste | HypothÃ¨se d'indÃ©pendance conditionnelle â†’ perspective trÃ¨s diffÃ©rente des autres modÃ¨les |

**La clÃ© : LA DIVERSITÃ‰** - Des modÃ¨les aux hypothÃ¨ses diffÃ©rentes capturent des patterns complÃ©mentaires.

#### ModÃ¨les de Niveau 1 (Meta-Learners)

| Meta-ModÃ¨le | Avantages | InconvÃ©nients | Quand l'utiliser |
|-------------|-----------|---------------|------------------|
| **Ridge (L2)** | RÃ©gularisation empÃªche l'overfitting, interprÃ©table (montre les poids de chaque modÃ¨le), stable | Ne capture pas les interactions non-linÃ©aires entre prÃ©dictions | Bon choix par dÃ©faut, surtout avec peu de meta-features |
| **XGBoost** | Capture les interactions non-linÃ©aires entre prÃ©dictions de base, excellente performance | Plus complexe, risque d'overfitting avec peu de features | Quand les patterns sont complexes et qu'on a suffisamment de donnÃ©es |

### Stacking (OOF) vs Blending

| Aspect | Stacking (OOF) | Blending (Holdout) |
|--------|----------------|-------------------|
| **MÃ©thode** | Validation croisÃ©e K-fold | Split train/blend/test fixe |
| **DonnÃ©es utilisÃ©es** | 100% pour entraÃ®nement | ~75% seulement |
| **Variance** | Plus faible (moyenne sur K folds) | Plus Ã©levÃ©e (1 seul split) |
| **ComplexitÃ©** | Plus Ã©levÃ©e (K Ã— N modÃ¨les) | Plus simple |
| **Risque overfitting** | Plus faible | Plus Ã©levÃ© |
| **Recommandation** | âœ… Ã€ privilÃ©gier | Acceptable pour prototypage rapide |

---

## Datasets utilisÃ©s

### Dataset 1 : Ames Housing (Immobilier)

- **Source** : [AmesHousing R package](https://cran.r-project.org/package=AmesHousing) - Dean De Cock (2011)
- **Taille** : 2,930 observations Ã— 82 variables
- **Type de features** : Mixte (numÃ©riques + catÃ©gorielles)
- **Cible** : `Sale_Price` â†’ transformÃ© en classification binaire (High/Low par rapport Ã  la mÃ©diane ~$160,000)
- **Domaine** : Immobilier, prix des maisons Ã  Ames, Iowa
- **Baseline accuracy** : ~90% (modÃ¨les individuels)

**Pourquoi ce dataset ?**
- Riche en features hÃ©tÃ©rogÃ¨nes â†’ teste la robustesse des modÃ¨les face Ã  la complexitÃ©
- Taille suffisante pour le stacking sans surapprentissage
- ProblÃ¨me rÃ©aliste et bien documentÃ© dans la littÃ©rature

### Dataset 2 : Pima Indians Diabetes (MÃ©dical)

- **Source** : [mlbench R package](https://cran.r-project.org/package=mlbench) - National Institute of Diabetes and Digestive and Kidney Diseases
- **Taille** : 768 observations Ã— 8 variables
- **Type de features** : Uniquement numÃ©riques (glucose, pression artÃ©rielle, IMC, Ã¢ge, etc.)
- **Cible** : `diabetes` (pos/neg - prÃ©sence de diabÃ¨te)
- **Domaine** : MÃ©dical, dÃ©pistage du diabÃ¨te
- **Baseline accuracy** : ~75% (modÃ¨les individuels)

**Pourquoi ce dataset ?**
- **Domaine diffÃ©rent** : mÃ©dical vs immobilier â†’ teste la gÃ©nÃ©ralisation du stacking
- **Taille rÃ©duite** : 768 vs 2,930 observations â†’ Ã©value la robustesse du stacking avec moins de donnÃ©es
- **Features uniquement numÃ©riques** : pas de variables catÃ©gorielles â†’ simplifie le preprocessing
- **Bruit et valeurs manquantes** : valeurs impossibles (0 pour glucose, pression) â†’ teste la robustesse
- **ProblÃ¨me plus difficile** : baseline ~75% vs ~90% pour Ames â†’ teste si le stacking aide davantage sur un problÃ¨me complexe

### Dataset 3 : Bank Marketing (Financial/Commercial)

- **Source** : [UCI ML Repository](https://archive.ics.uci.edu/ml/datasets/bank+marketing) - Portuguese Banking Institution
- **Taille** : 41,188 observations Ã— 20 variables
- **Type de features** : Mixte (numÃ©riques + catÃ©gorielles)
- **Cible** : `y` (yes/no - client a souscrit un dÃ©pÃ´t Ã  terme)
- **Domaine** : Finance / Marketing, campagnes de marketing direct par tÃ©lÃ©phone
- **Baseline accuracy** : ~90% (Random Forest)

**Pourquoi ce dataset ?**
- **Taille adÃ©quate** : 41,188 obs >> Ionosphere (351) â†’ prÃ©vient le surapprenti ssage du meta-modÃ¨le
- **Real-world data** : donnÃ©es financiÃ¨res/commerciales rÃ©elles, non contrÃ´lÃ©es
- **Preprocessing complexe** : variables catÃ©gorielles (nombreuses) requiÃ¨rent encoding (comme Ames)
- **Classes dÃ©sÃ©quilibrÃ©es** : 88.7% no, 11.3% yes â†’ scenario rÃ©aliste et problÃ©matique
- **Baseline 90%** â†’ laisse de la place pour que le stacking apporte des gains
- **ComplÃ©ment multi-domaines** : Immobilier (Ames) + MÃ©dical (Pima) + Finance (Bank Marketing)

### Pourquoi comparer trois datasets ?

La comparaison multi-datasets permet de tirer des **conclusions gÃ©nÃ©ralisables** :
1. **Impact de la taille** : Le stacking profite-t-il davantage d'un dataset plus grand ?
2. **Impact de la complexitÃ©** : Sur quel type de problÃ¨me (facile vs difficile) le stacking apporte-t-il le plus ?
3. **Impact de la diversitÃ© des features** : Les features mixtes vs purement numÃ©riques vs haute dimension affectent-elles le gain ?
4. **Impact de la diversitÃ© des modÃ¨les** : La corrÃ©lation entre prÃ©dictions de base est-elle le facteur clÃ© du succÃ¨s du stacking ?
5. **GÃ©nÃ©ralisation inter-domaines** : Le stacking est-il universel ou spÃ©cifique au domaine ?

---

## Structure du Projet

```
ensemble_ml_Stacking/
â”œâ”€â”€ README.md                          # Ce fichier
â”œâ”€â”€ data/
â”‚   â””â”€â”€ README.md                      # Instructions pour les datasets
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ stacking_dual_dataset.ipynb    # ğŸ¯ NOTEBOOK PRINCIPAL (Ã  exÃ©cuter)
â”œâ”€â”€ diagrams/
â”‚   â””â”€â”€ stacking_architecture.drawio   # Architecture visuelle (draw.io)
â”œâ”€â”€ output/                            # ğŸ“Š RÃ©sultats gÃ©nÃ©rÃ©s aprÃ¨s exÃ©cution
â”‚   â”œâ”€â”€ results_ames_housing.csv
â”‚   â”œâ”€â”€ results_pima_diabetes.csv
â”‚   â”œâ”€â”€ results_bank_marketing.csv
â”‚   â”œâ”€â”€ correlation_matrix_*.csv
â”‚   â”œâ”€â”€ cross_dataset_comparison.csv
â”‚   â”œâ”€â”€ corrplot_*.png
â”‚   â”œâ”€â”€ accuracy_comparison_*.png
â”‚   â”œâ”€â”€ roc_curves_*.png
â”‚   â”œâ”€â”€ training_times_*.png
â”‚   â”œâ”€â”€ correlation_vs_stacking_gain.png
â”‚   â”œâ”€â”€ dataset_profile_comparison.png
â”‚   â””â”€â”€ ...
â””â”€â”€ images/                            # (vide - pour exports supplÃ©mentaires)
```

---

## Installation & ExÃ©cution

### PrÃ©requis

- **R** (â‰¥ 4.0)
- **IRkernel** (pour exÃ©cuter R dans Jupyter)
- **Jupyter Notebook** / **VS Code** avec extension Jupyter

### Installation des packages R

Le notebook installe automatiquement les packages manquants, mais vous pouvez les installer manuellement :

```r
install.packages(c(
  "caret", "randomForest", "e1071", "class", "naivebayes",
  "glmnet", "xgboost", "ggplot2", "corrplot", "reshape2",
  "dplyr", "tidyr", "pROC", "scales", "gridExtra",
  "data.table", "AmesHousing", "mlbench"
))
```

### Installation IRkernel (si pas dÃ©jÃ  fait)

```r
install.packages('IRkernel')
IRkernel::installspec()
```

### ExÃ©cution du projet

1. **Cloner le dÃ©pÃ´t** :
```bash
git clone https://github.com/votre-username/ensemble_ml_Stacking.git
cd ensemble_ml_Stacking
```

2. **Ouvrir le notebook principal** :
```bash
jupyter notebook notebooks/stacking_dual_dataset.ipynb
```
Ou ouvrir dans VS Code avec l'extension Jupyter.

3. **ExÃ©cuter toutes les cellules** (`Run All`) :
   - Le notebook charge automatiquement les trois datasets
   - GÃ©nÃ¨re tous les modÃ¨les, prÃ©dictions et visualisations
   - Sauvegarde tous les rÃ©sultats dans `output/`

4. **Consulter les rÃ©sultats** :
   - Tableaux de performance dans le notebook
   - Fichiers CSV et graphiques dans le dossier `output/`

---

## MÃ©thodologie dÃ©taillÃ©e

### 1. PrÃ©traitement

**Pour Ames Housing :**
- Transformation de `Sale_Price` en classification binaire (High/Low basÃ© sur la mÃ©diane)
- SÃ©lection de 19 features numÃ©riques + 5 catÃ©gorielles (basÃ© sur la corrÃ©lation)
- Imputation des valeurs manquantes (mÃ©diane pour numÃ©riques)
- One-hot encoding des variables catÃ©gorielles
- Suppression des features Ã  variance quasi-nulle
- RÃ©sultat : **21 features finales** aprÃ¨s preprocessing

**Pour Pima Indians Diabetes :**
- Correction des valeurs impossibles : 0 pour glucose, pression, etc. â†’ remplacÃ©s par NA
- Imputation par la mÃ©diane
- Pas d'encoding nÃ©cessaire (dÃ©jÃ  purement numÃ©rique)
- RÃ©sultat : **8 features** (toutes numÃ©riques)

**Pour Bank Marketing :**
- Suppression de la colonne `duration` (fuite d'information - contient des infos post-appel)
- Identification des 10 colonnes catÃ©gorielles et 8 numÃ©riques
- One-hot encoding des variables catÃ©gorielles
- Suppression des features Ã  variance quasi-nulle
- RÃ©sultat : **52 features** (aprÃ¨s encoding des catÃ©gorielles)

**Commun aux trois :**
- Split **80% train / 20% test** (stratifiÃ© pour conserver les proportions de classes)
- **Normalisation** (centrage-rÃ©duction) : indispensable pour SVM et KNN sensibles Ã  l'Ã©chelle

### 2. Validation CroisÃ©e Out-of-Fold (OOF)

```
Pour chaque modÃ¨le de base :
  Pour chaque fold k (k=1..5) :
    1. EntraÃ®ner le modÃ¨le sur les 4 autres folds
    2. PrÃ©dire les probabilitÃ©s sur le fold k â†’ stockÃ©es dans la matrice OOF (train)
    3. PrÃ©dire les probabilitÃ©s sur le test set â†’ moyennÃ©es sur les 5 folds

RÃ©sultat : Matrice OOF train (N_train Ã— 5) et test (N_test Ã— 5)
```

**Pourquoi l'OOF ?**
- âœ… **Pas de data leakage** : Chaque prÃ©diction OOF est faite sur des donnÃ©es non vues pendant l'entraÃ®nement de ce fold
- âœ… **100% des donnÃ©es** sont utilisÃ©es pour gÃ©nÃ©rer les mÃ©ta-features (vs blending qui "perd" des donnÃ©es)
- âœ… **Estimations plus stables** : Moyenne sur 5 folds rÃ©duit la variance des prÃ©dictions

### 3. EntraÃ®nement du Meta-ModÃ¨le

**DonnÃ©es d'entrÃ©e du meta-modÃ¨le :**
- **Features** : Les 5 colonnes de prÃ©dictions OOF (une par modÃ¨le de base)
- **Target** : Les vraies classes du training set

**Ridge Regression (L2) :**
- Cross-validation pour trouver le `lambda` optimal (paramÃ¨tre de rÃ©gularisation)
- Retourne les **poids** de chaque modÃ¨le de base â†’ interprÃ©tabilitÃ©
- Combine linÃ©airement les prÃ©dictions de base

**XGBoost :**
- ParamÃ¨tres conservateurs (`max_depth=2`) pour Ã©viter l'overfitting avec seulement 5 features
- Cross-validation pour trouver le nombre optimal d'itÃ©rations (early stopping)
- Peut capturer les **interactions non-linÃ©aires** entre les prÃ©dictions de base

### 4. Blending (Comparaison)

- Split : **75% train / 25% blend** (du training set initial)
- ModÃ¨les de base entraÃ®nÃ©s sur les 75%
- PrÃ©dictions sur le blend set (25%) â†’ mÃ©ta-features
- Meta-modÃ¨le entraÃ®nÃ© sur ces prÃ©dictions
- **RÃ©sultat attendu** : Performance lÃ©gÃ¨rement infÃ©rieure Ã  l'OOF (moins de donnÃ©es, plus de variance)

---

## RÃ©sultats attendus et analyses

### MÃ©triques de comparaison

| MÃ©trique | Description | Pourquoi l'utiliser |
|----------|-------------|---------------------|
| **Accuracy** | Taux de classification correcte | Mesure globale de performance |
| **AUC-ROC** | Aire sous la courbe ROC | CapacitÃ© de discrimination entre classes |
| **Precision** | Proportion de vrais positifs parmi les prÃ©dictions positives | Important si le coÃ»t des faux positifs est Ã©levÃ© |
| **Recall** | Proportion de vrais positifs parmi les positifs rÃ©els | Important si le coÃ»t des faux nÃ©gatifs est Ã©levÃ© |
| **F1-Score** | Moyenne harmonique de Precision et Recall | Ã‰quilibre entre les deux |
| **Temps d'entraÃ®nement** | CoÃ»t computationnel | Compromis performance/temps |

### Visualisations produites

Le notebook gÃ©nÃ¨re automatiquement **14+ visualisations par dataset** :

**Analyse de la diversitÃ© (Niveau 0) :**
1. **Matrice de corrÃ©lation** des prÃ©dictions OOF (corrplot + heatmap)
   - InterprÃ©tation : CorrÃ©lation < 0.7 = bonne diversitÃ©
2. **Distribution des probabilitÃ©s prÃ©dites** par modÃ¨le (densitÃ© par classe)
   - Montre si les modÃ¨les ont des biais diffÃ©rents

**Comparaison de performance :**
3. **Barplot des Accuracy** (Stacking vs Individuels vs Blending)
4. **Courbes ROC superposÃ©es** avec AUC
5. **Comparaison multi-mÃ©triques** (Accuracy/AUC/F1)

**Analyse temporelle :**
6. **Temps d'entraÃ®nement** par modÃ¨le (barplot)
7. **Compromis Performance vs Temps** (scatter plot)

**Analyse cross-dataset (3 datasets) :**
8. **Comparaison side-by-side** des accuracy (Ames vs Pima vs Bank Marketing)
9. **Gains du stacking** (points de pourcentage) par mÃ©trique et dataset
10. **CorrÃ©lations Niveau 0** comparÃ©es entre datasets
11. **CorrÃ©lation vs Gain du Stacking** : Diagramme montrant la relation entre diversitÃ© des modÃ¨les et gain du stacking
12. **Profil comparatif des 3 datasets** : Taille, features, corrÃ©lation, gain normalisÃ©s

### Conclusions attendues

**HypothÃ¨ses Ã  vÃ©rifier :**

1. **Le stacking amÃ©liore-t-il toujours les performances ?**
   - DÃ©pend de la diversitÃ© des modÃ¨les de base (corrÃ©lation des prÃ©dictions)
   - Si corrÃ©lation > 0.9 : gain marginal ou nÃ©gatif
   - Si corrÃ©lation < 0.8 : gain significatif possible

2. **Impact de la taille du dataset**
   - Bank Marketing (41,188 obs) devrait montrer un gain de stacking trÃ¨s stable
   - Ames (2,930 obs) devrait avoir des gains stables
   - Pima (768 obs) risque un surapprentissage du meta-modÃ¨le

3. **Impact de la diversitÃ© des modÃ¨les (FACTEUR CLÃ‰)**
   - La corrÃ©lation entre prÃ©dictions de base dÃ©termine le succÃ¨s du stacking
   - Bank Marketing (52 features mixtes) devrait produire des patterns intÃ©ressants
   - Ames (haute corrÃ©lation ~0.94) â†’ gain minimal

4. **OOF vs Blending**
   - OOF devrait systÃ©matiquement surpasser le blending (+0.5% Ã  +2% d'accuracy)
   - Ã‰cart plus grand sur petit dataset (Pima) oÃ¹ "perdre" 25% des donnÃ©es a plus d'impact

5. **Choix du meta-modÃ¨le (Ridge vs XGBoost)**
   - Ridge : plus stable, surtout sur Pima avec peu de donnÃ©es
   - XGBoost : peut surpasser Ridge sur Ames avec plus de donnÃ©es et patterns complexes

---

## Concepts clÃ©s expliquÃ©s

### Pourquoi le Stacking fonctionne-t-il ?

1. **DiversitÃ© = ComplÃ©mentaritÃ©**
   - Des modÃ¨les aux hypothÃ¨ses diffÃ©rentes font des erreurs sur des exemples diffÃ©rents
   - Le meta-modÃ¨le apprend Ã  exploiter leurs forces respectives

2. **Correction d'erreurs**
   - Si un modÃ¨le est systÃ©matiquement trop confiant ou pas assez, le meta-modÃ¨le peut corriger ce biais
   - Exemple : Si RF prÃ©dit toujours "High" avec 0.9 de probabilitÃ© mais se trompe 20% du temps, le meta-modÃ¨le apprendra Ã  downweighter ces prÃ©dictions

3. **RÃ©duction de variance**
   - ThÃ©orÃ¨me de la "sagesse des foules" : La moyenne de prÃ©dicteurs indÃ©pendants rÃ©duit la variance
   - Le stacking va plus loin qu'une simple moyenne : il apprend la **pondÃ©ration optimale**

4. **Non-linÃ©aritÃ© (avec XGBoost)**
   - XGBoost peut apprendre des rÃ¨gles comme "Si RF dit High ET SVM dit Low, alors Low"
   - Capture les interactions entre modÃ¨les de base

### Pourquoi la validation OOF Ã©vite le data leakage ?

**Mauvaise approche (avec leakage) :**
```
1. EntraÃ®ner RF sur tout le train set
2. PrÃ©dire sur tout le train set â†’ mÃ©ta-features
3. EntraÃ®ner Ridge sur ces mÃ©ta-features
âŒ ProblÃ¨me : RF a dÃ©jÃ  vu ces donnÃ©es, prÃ©dictions trop optimistes
```

**Bonne approche (OOF) :**
```
1. Pour le fold 1 : EntraÃ®ner RF sur folds 2-5, prÃ©dire sur fold 1
2. Pour le fold 2 : EntraÃ®ner RF sur folds 1,3-5, prÃ©dire sur fold 2
...
âœ… RÃ©sultat : Chaque prÃ©diction OOF est out-of-sample
```

### Le stacking est-il toujours la meilleure approche ?

**Non ! Le stacking ne vaut la peine que si :**
- âœ… Les modÃ¨les de base sont **vraiment diversifiÃ©s** (corrÃ©lations < 0.8)
- âœ… Vous avez **suffisamment de donnÃ©es** (rÃ¨gle empirique : N > 500 pour le train)
- âœ… Le **coÃ»t computationnel** est acceptable (5 modÃ¨les Ã— K folds = 25 entraÃ®nements)
- âœ… Le problÃ¨me est **suffisamment complexe** (si un modÃ¨le simple suffit, le stacking n'apportera rien)

**Quand utiliser des alternatives :**
- **Vote majoritaire** : Si vous voulez quelque chose de simple et interprÃ©table
- **Simple averaging** : Si vos modÃ¨les ont des performances similaires
- **Un seul modÃ¨le bien tunnÃ©** : Si vous manquez de donnÃ©es ou de temps

---

## RÃ©fÃ©rences acadÃ©miques

### Stacking et Ensemble Learning
- **Wolpert, D.H. (1992)**. *Stacked Generalization*. Neural Networks, 5(2), 241-259.
  - ğŸ“„ Article fondateur du stacking
- **Breiman, L. (1996)**. *Stacked Regressions*. Machine Learning, 24(1), 49-64.
  - ğŸ“„ Extension du stacking aux problÃ¨mes de rÃ©gression

### Datasets
- **De Cock, D. (2011)**. *Ames, Iowa: Alternative to the Boston Housing Data*. Journal of Statistics Education, 19(3).
  - ğŸ“„ Description du dataset Ames Housing
- **Smith, J.W., et al. (1988)**. *Using the ADAP learning algorithm to forecast the onset of diabetes mellitus*. Proceedings of the Symposium on Computer Applications and Medical Care, 261-265.
  - ğŸ“„ Dataset Pima Indians Diabetes original
- **Moro, S., Cortez, P., & Rita, P. (2014)**. *A data-driven approach to predict the success of bank telemarketing*. Decision Support Systems, 62, 22-31.
  - ğŸ“„ Dataset Bank Marketing original

### ThÃ©orie de l'Ensemble Learning
- **Hastie, T., Tibshirani, R., & Friedman, J. (2009)**. *The Elements of Statistical Learning*. Springer.
  - ğŸ“– Chapitre 8 : Model Inference and Averaging
- **Zhou, Z.-H. (2012)**. *Ensemble Methods: Foundations and Algorithms*. CRC Press.
  - ğŸ“– RÃ©fÃ©rence complÃ¨te sur les mÃ©thodes d'ensemble

---

## Auteur

- **Nom**: Bellatreche Mohamed Amine
- **GitHub**: [aminedubs](https://github.com/amine-dubs)
- **Contact**: aminedubs@gmail.com

---

## Licence

Ce projet est sous licence MIT - voir le fichier [LICENSE](LICENSE) pour plus de dÃ©tails.

---

## FAQ

**Q : Combien de temps prend l'exÃ©cution complÃ¨te ?**
R : ~5-15 minutes selon votre machine (principalement le SVM avec validation croisÃ©e).

**Q : Puis-je utiliser mes propres datasets ?**
R : Oui ! Le code est modulaire. Utilisez la fonction `run_stacking_pipeline()` avec vos donnÃ©es preprocessÃ©es (X_train, y_train, X_test, y_test).

**Q : Pourquoi 5 folds et pas 10 ?**
R : Compromis variance/bias. 5 folds est standard pour des datasets de taille moyenne. Avec Pima (768 obs), 10 folds donnerait des folds trop petits (68 obs/fold).

**Q : Le stacking marche-t-il pour la rÃ©gression ?**
R : Oui ! MÃªme principe, remplacez juste les mÃ©triques de classification par MAE/RMSE/RÂ².

**Q : Dois-je toujours utiliser Ridge ET XGBoost comme meta-modÃ¨les ?**
R : Non, c'est pour comparer. En production, choisissez-en un seul (souvent Ridge pour la simplicitÃ©).

---

## Prochaines Ã©tapes possibles

1. **Feature engineering avancÃ©** : CrÃ©er des interactions, polynÃ´mes, etc.
2. **Hyperparameter tuning** : Grid search sur les modÃ¨les de base
3. **Stacking multi-niveaux** : Ajouter un 3Ã¨me niveau (attention Ã  l'overfitting !)
4. **Autres datasets** : Tester sur d'autres domaines (finance, NLP, vision...)
5. **Deployment** : Packager le meilleur modÃ¨le avec FastAPI/Plumber
