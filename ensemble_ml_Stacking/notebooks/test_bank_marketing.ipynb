{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test: Bank Marketing Dataset\n",
    "Testing if this real-world dataset produces good stacking gains\n",
    "\n",
    "## How to get the dataset:\n",
    "1. Download from: https://archive.ics.uci.edu/ml/datasets/bank+marketing\n",
    "2. This script will download and extract automatically\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Download and extract from UCI\n",
    "library(caret)\n",
    "library(dplyr)\n",
    "set.seed(42)\n",
    "\n",
    "cat(\"Downloading Bank Marketing dataset...\\n\")\n",
    "url <- \"https://archive.ics.uci.edu/ml/machine-learning-databases/00222/bank-additional.zip\"\n",
    "temp_zip <- tempfile(fileext = \".zip\")\n",
    "download.file(url, temp_zip, mode = \"wb\")\n",
    "unzip(temp_zip, exdir = tempdir())\n",
    "bank <- read.csv(file.path(tempdir(), \"bank-additional/bank-additional-full.csv\"), sep=\";\")\n",
    "\n",
    "cat(\"Dataset Info:\\n\")\n",
    "cat(\"Dimensions:\", nrow(bank), \"x\", ncol(bank), \"\\n\")\n",
    "cat(\"Target variable (y): yes/no subscription\\n\")\n",
    "cat(\"Classes:\\n\")\n",
    "print(table(bank$y))\n",
    "cat(\"\\nProportions:\", round(prop.table(table(bank$y)) * 100, 1), \"%\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "bank <- bank %>% \n",
    "  select(-duration) %>%  # Remove duration (leaks target info for prediction)\n",
    "  rename(target = y)     # Rename target column\n",
    "\n",
    "# Convert target to factor\n",
    "bank$target <- as.factor(bank$target)\n",
    "\n",
    "cat(\"Features after selection:\", ncol(bank)-1, \"\\n\\n\")\n",
    "\n",
    "# Identify numeric and categorical columns\n",
    "numeric_cols <- names(bank)[sapply(bank, is.numeric)]\n",
    "cat_cols <- names(bank)[sapply(bank, is.factor) | sapply(bank, is.character)]\n",
    "cat_cols <- cat_cols[cat_cols != \"target\"]\n",
    "\n",
    "cat(\"Numeric features:\", length(numeric_cols) - 1, \"\\n\")\n",
    "cat(\"Categorical features:\", length(cat_cols), \"\\n\\n\")\n",
    "\n",
    "# One-hot encode categorical variables\n",
    "bank_encoded <- bank\n",
    "for (col in cat_cols) {\n",
    "  dummies <- model.matrix(~ . - 1, data.frame(bank_encoded[[col]]))\n",
    "  colnames(dummies) <- paste0(col, \"_\", colnames(dummies))\n",
    "  bank_encoded[[col]] <- NULL\n",
    "  bank_encoded <- cbind(bank_encoded, dummies[, -ncol(dummies)])  # Drop one for reference\n",
    "}\n",
    "\n",
    "cat(\"Final feature count:\", ncol(bank_encoded) - 1, \"\\n\")\n",
    "cat(\"Class balance remains:\", table(bank_encoded$target), \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Split data\n",
    "train_idx <- createDataPartition(bank_encoded$target, p = 0.8, list = FALSE)\n",
    "X_train <- bank_encoded[train_idx, -which(names(bank_encoded) == \"target\")]\n",
    "y_train <- bank_encoded$target[train_idx]  # Keep as factor\n",
    "X_test <- bank_encoded[-train_idx, -which(names(bank_encoded) == \"target\")]\n",
    "y_test <- bank_encoded$target[-train_idx]  # Keep as factor\n",
    "\n",
    "cat(\"Train:\", nrow(X_train), \"| Test:\", nrow(X_test), \"\\n\")\n",
    "cat(\"Features:\", ncol(X_train), \"\\n\")\n",
    "cat(\"y_train class:\", class(y_train), \"\\n\")\n",
    "cat(\"Class balance - Train:\", table(y_train), \"\\n\")\n",
    "cat(\"Class balance - Test:\", table(y_test), \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Quick baseline test\n",
    "library(randomForest)\n",
    "library(pROC)\n",
    "\n",
    "# Standardize\n",
    "preproc <- preProcess(X_train, method = c(\"center\", \"scale\"))\n",
    "X_train_scaled <- predict(preproc, X_train)\n",
    "X_test_scaled <- predict(preproc, X_test)\n",
    "\n",
    "# Train RF\n",
    "cat(\"Training Random Forest (this may take ~60 seconds)...\\n\")\n",
    "rf_test <- randomForest(x = X_train_scaled, y = y_train, ntree = 500)\n",
    "rf_pred_prob <- predict(rf_test, X_test_scaled, type = \"prob\")[, 2]  # Get probabilities for 'yes'\n",
    "rf_pred_class <- predict(rf_test, X_test_scaled)  # Get class predictions\n",
    "rf_acc <- mean(rf_pred_class == y_test)\n",
    "\n",
    "cat(\"\\n\\nRandom Forest Results:\\n\")\n",
    "cat(\"Accuracy:\", round(rf_acc, 4), \"\\n\")\n",
    "\n",
    "# AUC\n",
    "roc_obj <- roc(as.numeric(y_test) - 1, rf_pred_prob, quiet = TRUE)\n",
    "cat(\"AUC-ROC:\", round(auc(roc_obj), 4), \"\\n\")\n",
    "\n",
    "if (rf_acc >= 0.85 && rf_acc <= 0.92) {\n",
    "  cat(\"\\n✓ This dataset has IDEAL baseline (85-92% range)\\n\")\n",
    "  cat(\"✓ Room for stacking to improve!\\n\")\n",
    "  cat(\"✓ Proceed to integrate into main project\\n\")\n",
    "} else if (rf_acc < 0.85) {\n",
    "  cat(\"\\n⚠ Baseline is LOW (<85%). May need different preprocessing.\\n\")\n",
    "} else {\n",
    "  cat(\"\\n⚠ Baseline is HIGH (>92%). Ceiling effect - limited room for improvement.\\n\")\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "- **Dataset**: Bank Marketing (real-world financial data)\n",
    "- **Size**: 41,188 observations (excellent for stacking)\n",
    "- **Features**: ~50+ (after encoding) - mixed real-world data\n",
    "- **Characteristics**:\n",
    "  - Imbalanced (88% no, 12% yes) - realistic minority class problem\n",
    "  - Mixed features requiring preprocessing\n",
    "  - Real-world noise\n",
    "  - Similar complexity to Ames Housing\n",
    "\n",
    "## Advantages over tested datasets:\n",
    "1. **Much larger**: 41,188 obs (vs Ionosphere 351 → prevents meta-model overfitting)\n",
    "2. **Real-world data**: Not synthetic/controlled like Ionosphere\n",
    "3. **Preprocessing required**: Like Ames (categorical encoding)\n",
    "4. **Good baseline for improvement**: Should leave room for stacking gains\n",
    "\n",
    "## If baseline is 85-92%:\n",
    "- ✓ Proceed to integrate into main project as Dataset 3\n",
    "- ✓ Replace Ionosphere (which had only 351 obs and ceiling effect)\n",
    "- ✓ Will complement Ames (real estate) + Pima (medical) with financial/commercial data\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.2.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
